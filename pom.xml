<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>com.versh</groupId>
	<artifactId>sparkSpikes</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>sparkSpikes</name>
	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<java.version>1.8</java.version>
		<maven.compiler.source>${java.version}</maven.compiler.source>
		<maven.compiler.target>${java.version}</maven.compiler.target>
		<maven.version>3.6.3</maven.version>
		<sbt.project.name>spark</sbt.project.name>
		<slf4j.version>1.7.16</slf4j.version>
		<log4j.version>1.2.17</log4j.version>
		<hadoop.version>2.7.4</hadoop.version>
		<protobuf.version>2.5.0</protobuf.version>
		<yarn.version>${hadoop.version}</yarn.version>
		<zookeeper.version>3.4.14</zookeeper.version>
		<curator.version>2.7.1</curator.version>
		<hive.group>org.apache.hive</hive.group>
		<hive.classifier>core</hive.classifier>
		<!-- Version used in Maven Hive dependency -->
		<hive.version>2.3.6</hive.version>
		<hive23.version>2.3.6</hive23.version>
		<!-- Version used for internal directory structure -->
		<hive.version.short>2.3</hive.version.short>
		<!-- note that this should be compatible with Kafka brokers version 0.10 
			and up -->
		<kafka.version>2.4.0</kafka.version>
		<derby.version>10.12.1.1</derby.version>
		<parquet.version>1.10.1</parquet.version>
		<orc.version>1.5.9</orc.version>
		<orc.classifier></orc.classifier>
		<hive.parquet.group>com.twitter</hive.parquet.group>
		<hive.parquet.version>1.6.0</hive.parquet.version>
		<jetty.version>9.4.18.v20190429</jetty.version>
		<javaxservlet.version>3.1.0</javaxservlet.version>
		<chill.version>0.9.5</chill.version>
		<ivy.version>2.4.0</ivy.version>
		<oro.version>2.0.8</oro.version>
		<codahale.metrics.version>4.1.1</codahale.metrics.version>
		<avro.version>1.8.2</avro.version>
		<avro.mapred.classifier>hadoop2</avro.mapred.classifier>
		<aws.kinesis.client.version>1.12.0</aws.kinesis.client.version>
		<!-- Should be consistent with Kinesis client dependency -->
		<aws.java.sdk.version>1.11.271</aws.java.sdk.version>
		<!-- the producer is used in tests -->
		<aws.kinesis.producer.version>0.12.8</aws.kinesis.producer.version>
		<!-- org.apache.httpcomponents/httpclient -->
		<commons.httpclient.version>4.5.6</commons.httpclient.version>
		<commons.httpcore.version>4.4.12</commons.httpcore.version>
		<!-- commons-httpclient/commons-httpclient -->
		<httpclient.classic.version>3.1</httpclient.classic.version>
		<commons.math3.version>3.4.1</commons.math3.version>
		<!-- managed up from 3.2.1 for SPARK-11652 -->
		<commons.collections.version>3.2.2</commons.collections.version>
		<scala.version>2.12.10</scala.version>
		<scala.binary.version>2.11</scala.binary.version>
		<scalafmt.parameters>--test</scalafmt.parameters>
		<!-- for now, not running scalafmt as part of default verify pipeline -->
		<scalafmt.skip>true</scalafmt.skip>
		<codehaus.jackson.version>1.9.13</codehaus.jackson.version>
		<fasterxml.jackson.version>2.10.0</fasterxml.jackson.version>
		<snappy.version>1.1.7.3</snappy.version>
		<netlib.java.version>1.1.2</netlib.java.version>
		<commons-codec.version>1.10</commons-codec.version>
		<commons-io.version>2.4</commons-io.version>
		<!-- org.apache.commons/commons-lang/ -->
		<commons-lang2.version>2.6</commons-lang2.version>
		<!-- org.apache.commons/commons-lang3/ -->
		<commons-lang3.version>3.9</commons-lang3.version>
		<!-- org.apache.commons/commons-pool2/ -->
		<commons-pool2.version>2.6.2</commons-pool2.version>
		<datanucleus-core.version>4.1.17</datanucleus-core.version>
		<janino.version>3.0.15</janino.version>
		<jersey.version>2.30</jersey.version>
		<joda.version>2.10.5</joda.version>
		<jodd.version>3.5.2</jodd.version>
		<jsr305.version>3.0.0</jsr305.version>
		<libthrift.version>0.12.0</libthrift.version>
		<antlr4.version>4.7.1</antlr4.version>
		<jpam.version>1.1</jpam.version>
		<selenium.version>2.52.0</selenium.version>
		<htmlunit.version>2.22</htmlunit.version>
		<!-- Managed up from older version from Avro; sync with jackson-module-paranamer 
			dependency version -->
		<paranamer.version>2.8</paranamer.version>
		<maven-antrun.version>1.8</maven-antrun.version>
		<commons-crypto.version>1.0.0</commons-crypto.version>
		<!-- If you are changing Arrow version specification, please check ./python/pyspark/sql/utils.py, 
			and ./python/setup.py too. -->
		<arrow.version>0.15.1</arrow.version>
		<!-- org.fusesource.leveldbjni will be used except on arm64 platform. -->
		<leveldbjni.group>org.fusesource.leveldbjni</leveldbjni.group>

		<test.java.home>${java.home}</test.java.home>
		<test.exclude.tags></test.exclude.tags>
		<test.include.tags></test.include.tags>

		<!-- Package to use when relocating shaded classes. -->
		<spark.shade.packageName>org.sparkproject</spark.shade.packageName>

		<!-- Modules that copy jars to the build directory should do so under this 
			location. -->
		<jars.target.dir>${project.build.directory}/scala-${scala.binary.version}/jars</jars.target.dir>

		<!-- Allow modules to enable / disable certain build plugins easily. -->
		<build.testJarPhase>prepare-package</build.testJarPhase>
		<build.copyDependenciesPhase>none</build.copyDependenciesPhase>

		<!-- Dependency scopes that can be overridden by enabling certain profiles. 
			These profiles are declared in the projects that build assemblies. For other 
			projects the scope should remain as "compile", otherwise they are not available 
			during compilation if the dependency is transivite (e.g. "graphx/" depending 
			on "core/" and needing Hadoop classes in the classpath to compile). -->
		<hadoop.deps.scope>compile</hadoop.deps.scope>
		<hive.deps.scope>compile</hive.deps.scope>
		<hive.parquet.scope>provided</hive.parquet.scope>
		<hive.storage.version>2.7.1</hive.storage.version>
		<hive.storage.scope>compile</hive.storage.scope>
		<hive.common.scope>compile</hive.common.scope>
		<hive.llap.scope>compile</hive.llap.scope>
		<hive.serde.scope>compile</hive.serde.scope>
		<hive.shims.scope>compile</hive.shims.scope>
		<orc.deps.scope>compile</orc.deps.scope>
		<parquet.deps.scope>compile</parquet.deps.scope>
		<parquet.test.deps.scope>test</parquet.test.deps.scope>

		<!-- Overridable test home. So that you can call individual pom files directly 
			without things breaking. -->
		<spark.test.home>${session.executionRootDirectory}</spark.test.home>
		<CodeCacheSize>1g</CodeCacheSize>
	</properties>
	<dependencies>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka-0-8_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql-kafka-0-10_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.fasterxml.jackson.module</groupId>
			<artifactId>jackson-module-scala_${scala.binary.version}</artifactId>
			<version>2.9.7</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.github.scopt</groupId>
			<artifactId>scopt_${scala.binary.version}</artifactId>
			<version>3.7.1</version>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-graphx_${scala.binary.version}</artifactId>
			<version>2.3.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.scalanlp</groupId>
			<artifactId>breeze_${scala.binary.version}</artifactId>
			<version>1.0</version>
			<exclusions>
				<exclusion>
					<groupId>org.apache.commons</groupId>
					<artifactId>commons-math3</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

	</dependencies>
	<build>
		<sourceDirectory>src/main/scala</sourceDirectory>
		<testSourceDirectory>src/test/scala</testSourceDirectory>

		<plugins>
			<!-- mixed scala/java compile -->
			<plugin>
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.4.4</version>
				<executions>
					<execution>
						<id>compile</id>
						<goals>
							<goal>compile</goal>
						</goals>
						<phase>compile</phase>
					</execution>
					<execution>
						<id>test-compile</id>
						<goals>
							<goal>testCompile</goal>
						</goals>
						<phase>test-compile</phase>
					</execution>
					<execution>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>1.8</source>
					<target>1.8</target>
				</configuration>
			</plugin>
			<!-- for fatjar -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-assembly-plugin</artifactId>
				<version>3.1.0</version>
				<configuration>
					<descriptorRefs>
						<descriptorRef>jar-with-dependencies</descriptorRef>
					</descriptorRefs>
					<finalName>uber-sparkSpikes-0.0.1-SNAPSHOT</finalName>
					<appendAssemblyId>false</appendAssemblyId>
				</configuration>
				<executions>
					<execution>
						<id>assemble-all</id>
						<phase>package</phase>
						<goals>
							<goal>single</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<configuration>
					<archive>
						<manifest>
							<addClasspath>true</addClasspath>
							<mainClass>fully.qualified.MainClass</mainClass>
						</manifest>
					</archive>
				</configuration>
			</plugin>
		</plugins>
		<pluginManagement>
			<plugins>
				<!--This plugin's configuration is used to store Eclipse m2e settings 
					only. It has no influence on the Maven build itself. -->
				<plugin>
					<groupId>org.eclipse.m2e</groupId>
					<artifactId>lifecycle-mapping</artifactId>
					<version>1.0.0</version>
					<configuration>
						<lifecycleMappingMetadata>
							<pluginExecutions>
								<pluginExecution>
									<pluginExecutionFilter>
										<groupId>net.alchim31.maven</groupId>
										<artifactId>scala-maven-plugin</artifactId>
										<versionRange>[3.3.1,)</versionRange>
										<goals>
											<goal>compile</goal>
											<goal>testCompile</goal>
										</goals>
									</pluginExecutionFilter>
									<action>
										<execute />
									</action>
								</pluginExecution>
							</pluginExecutions>
						</lifecycleMappingMetadata>
					</configuration>
				</plugin>
			</plugins>
		</pluginManagement>
	</build>

</project>
